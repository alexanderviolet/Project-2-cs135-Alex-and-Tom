{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c86c0e9",
   "metadata": {},
   "source": [
    "# Tom and Alex Violet Project 2\n",
    "# April 13, 2025\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ea1118",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from CollabFilterOneVectorPerItem import CollabFilterOneVectorPerItem\n",
    "from train_valid_test_loader import load_train_valid_test_datasets\n",
    "\n",
    "import autograd\n",
    "import autograd.numpy as ag_np\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "\n",
    "from surprise import SVD,KNNBasic\n",
    "from surprise import Dataset, Reader, accuracy\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise import model_selection\n",
    "\n",
    "from surprise import SVD, SVDpp\n",
    "from surprise import Dataset, Reader\n",
    "from surprise.model_selection import RandomizedSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-v0_8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc32cb5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------\n",
    "\n",
    "\n",
    "##LOADING DATA##\n",
    "reader = Reader(\n",
    "    line_format='user item rating', sep=',',\n",
    "    rating_scale=(1, 5), skip_lines=1)\n",
    "\n",
    "# train_data = Dataset.load_from_file(\n",
    "#     'data_movie_lens_100k/ratings_all_development_set.csv', reader=reader)\n",
    "# # print(train_set[:5])\n",
    "# train_set = train_data.build_full_trainset()\n",
    "# raw_ratings = train_set.build_testset()\n",
    "\n",
    "\n",
    "##MAKING MERGE DATA FRAME\n",
    "# df = pd.read_csv('data_movie_lens_100k/ratings_all_development_set.csv')\n",
    "# user_df = pd.read_csv('data_movie_lens_100k/user_info.csv')\n",
    "# movie_df = pd.read_csv('data_movie_lens_100k/movie_info.csv')\n",
    "# merged_df = pd.merge(df, user_df, on='user_id', how='inner')\n",
    "# merged_df = merged_df.drop(columns=['orig_user_id'])\n",
    "# merged_movie_df = pd.merge(merged_df, movie_df, on='item_id', how='inner')\n",
    "\n",
    "\n",
    "\n",
    "# user_df = pd.read_csv('data_movie_lens_100k/user_info.csv')'\n",
    "# print(merged_movie_df[:100])\n",
    "# data = Dataset.load_from_df(df[['user_id', 'item_id', 'rating']], reader)\n",
    "\n",
    "\n",
    "\n",
    "DATA_PATH = 'data_movie_lens_100k/' # TODO fixme: Path to where dataset csv files live on your system\n",
    "if not os.path.exists(os.path.join(DATA_PATH, 'select_movies.csv')):\n",
    "    try:\n",
    "        DATA_PATH = os.path.join(os.environ.get(\"HOME\", \"\"),\n",
    "                    'courses/cs135-25s-staffonly/proj_src/projB/data_movie_lens_100k/')\n",
    "        assert os.path.exists(os.path.join(DATA_PATH, 'select_movies.csv'))\n",
    "    except AssertionError:\n",
    "        print(\"Please store path to movie_lens_100k dataset in DATA_PATH\")\n",
    "assert os.path.exists(os.path.join(DATA_PATH, 'select_movies.csv'))\n",
    "\n",
    "\n",
    "df_masked = pd.read_csv(\"data_movie_lens_100k/ratings_masked_leaderboard_set.csv\")\n",
    "\n",
    "df_masked['user_id'] = df_masked['user_id'].astype(str)\n",
    "df_masked['item_id'] = df_masked['item_id'].astype(str)\n",
    "df_masked['rating'] = 0\n",
    "\n",
    "\n",
    "# Create a list of (uid, iid) pairs\n",
    "predict_pairs = list(zip(df_masked['user_id'], df_masked['item_id'],df_masked['rating']))\n",
    "\n",
    "\n",
    "dev_set = Dataset.load_from_file(\n",
    "   os.path.join(DATA_PATH, 'ratings_all_development_set.csv'), reader=reader)\n",
    "dev_set_for_fit = dev_set.build_full_trainset()\n",
    "dev_set_for_predict = dev_set_for_fit.build_testset()\n",
    "dev_set_for_fit.global_mean\n",
    "\n",
    "print(\"Global Mean: \", dev_set_for_fit.global_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61039aae",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "##TRAINING##---------------------------------------\n",
    "\n",
    "# param_grid = {\n",
    "#     # \"n_factors\": [1,2,5,7,10,50,100],\n",
    "#     # \"lr_all\": [0.0005,0.001,0.005,0.05]\n",
    "#     \"n_factors\": [50],\n",
    "#     \"lr_all\": [0.005]\n",
    "# }\n",
    "\n",
    "# param_grid = {\n",
    "#     # \"n_factors\": [20, 50, 100],        # Latent dimensions (embedding size)\n",
    "#     # \"lr_all\": [0.002, 0.005, 0.01],    # Learning rate for all parameters\n",
    "#     # \"reg_all\": [0.02, 0.05, 0.1],      # Regularization term for all parameters\n",
    "#     # \"n_epochs\": [10, 20, 30]\n",
    "#     \"n_factors\": [100],        # Latent dimensions (embedding size)\n",
    "#     \"lr_all\": [0.01],    # Learning rate for all parameters\n",
    "#     \"reg_all\": [0.1],      # Regularization term for all parameters\n",
    "#     \"n_epochs\": [30]          # Number of SGD iterations\n",
    "# }\n",
    "# model = model_selection.search.RandomizedSearchCV(SVDpp, param_grid, n_iter=1, measures=['mae'], refit=True, n_jobs=-1)\n",
    "# model.fit(dev_set) \n",
    "# print(\"Lowest MAE: \", model.best_score['mae'])\n",
    "# print(\"Best params:\", model.best_params['mae'])\n",
    "# best_model = model.best_estimator['mae']\n",
    "# best_model.fit(dev_set_for_fit)\n",
    "\n",
    "##TRAIN AND FIT\n",
    "best_model = SVDpp(n_factors=100, lr_all=0.01, reg_all=0.1, n_epochs=30)\n",
    "best_model.fit(dev_set_for_fit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c3a04a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# np.savetxt(\"predicted_ratings_leaderboard.txt\", predictions[:][3])\n",
    "\n",
    "\n",
    "# yproba1_te = best_model.test(dev_set_for_predict)\n",
    "\n",
    "# print(0 in dev_set_for_fit._raw2inner_id_users)\n",
    "# print(113 in dev_set_for_fit._raw2inner_id_items)\n",
    "# for i in range(25):\n",
    "#     print(yproba1_te[i][2],round(yproba1_te[i][3]))\n",
    "# print(yproba1_te)\n",
    "\n",
    "\n",
    "# Convert cv_results_ to a DataFrame\n",
    "# results_df = pd.DataFrame(model.cv_results)\n",
    "\n",
    "\n",
    "# Show just the params and corresponding mean MAE\n",
    "# print(results_df[['params', 'mean_test_mae']].sort_values(by='mean_test_mae'))\n",
    "\n",
    "# Global Mean:  3.529480398257623\n",
    "# ('772', '36', 3.0)\n",
    "# 3.0 3\n",
    "# 4.0 4\n",
    "# 3.0 3\n",
    "# 5.0 4\n",
    "# 3.0 3\n",
    "# 2.0 3\n",
    "# 4.0 4\n",
    "# 2.0 3\n",
    "# 4.0 4\n",
    "# 1.0 2\n",
    "# 5.0 4\n",
    "# 3.0 4\n",
    "# 3.0 4\n",
    "# 4.0 4\n",
    "# 3.0 3\n",
    "# 3.0 3\n",
    "# 4.0 4\n",
    "# 3.0 4\n",
    "# 2.0 2\n",
    "# 4.0 4\n",
    "# 4.0 3\n",
    "# 2.0 2\n",
    "# 1.0 2\n",
    "# 2.0 2\n",
    "# 4.0 3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
